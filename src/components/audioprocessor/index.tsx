import React, { useState, useRef, useEffect } from 'react';
import axios from 'axios';
import { FaMicrophone, FaStop } from 'react-icons/fa'; // ğŸ”¥ ë§ˆì´í¬ & ì •ì§€ ì•„ì´ì½˜ ì¶”ê°€
import styled, { keyframes, css } from 'styled-components';
import { Button, FileForm } from './Styled';
import * as lame from '@breezystack/lamejs';

const API_KEY = '9908b0de5b704b80a20bb799d7803ad9';

interface Transcript {
  speaker: number;
  text: string;
}

interface Props {
  onTranscript: (transcript: Transcript[]) => void;
}

const pulse = keyframes`
  0% { box-shadow: 0 0 10px rgba(255, 0, 0, 0.3); }
  50% { box-shadow: 0 0 20px rgba(255, 0, 0, 0.7); }
  100% { box-shadow: 0 0 10px rgba(255, 0, 0, 0.3); }
`;

const RecorderContainer = styled.div`
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  padding: 20px;
`;

const Timer = styled.p`
  font-size: 18px;
  font-weight: bold;
  color: #333;
`;

const RecordButton = styled.button<{ $isRecording: boolean }>`
  background-color: ${(props) => (props.$isRecording ? '#ff4d4d' : '#4caf50')};
  border: none;
  color: white;
  width: 80px;
  height: 80px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 24px;
  cursor: pointer;
  transition: background 0.3s ease-in-out;
  box-shadow: ${(props) => (props.$isRecording ? '0 0 20px rgba(255, 0, 0, 0.7)' : '0 0 10px rgba(0, 255, 0, 0.7)')};

  ${(props) =>
    props.$isRecording &&
    css`
      animation: ${pulse} 1.5s infinite;
    `}
`;

const AudioProcessor: React.FC<Props> = ({ onTranscript }) => {
  const [loading, setLoading] = useState<boolean>(false);
  const [progress, setProgress] = useState<number>(0);
  const [file, setFile] = useState<File | null>(null);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null); // ğŸ”¥ ë…¹ìŒëœ íŒŒì¼ ì €ì¥ ë³€ìˆ˜
  const [time, setTime] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const recorderRef = useRef<MediaRecorder | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const timerRef = useRef<number | null>(null);

  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = event.target.files?.[0];
    if (selectedFile) {
      setFile(selectedFile);
      setAudioBlob(null);
    }
  };

  useEffect(() => {
    if (isRecording) {
      timerRef.current = window.setInterval(() => {
        setTime((prev) => prev + 1);
      }, 1000);
    } else {
      if (timerRef.current !== null) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }
  }, [isRecording]);

  const handleStartRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // âœ… ì§€ì›ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€ê²½: audio/wav âŒ â†’ audio/webm âœ…
      const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

      recorderRef.current = recorder;
      audioChunks.current = [];

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.current.push(event.data);
        }
      };

      recorder.onstop = async () => {
        const webmBlob = new Blob(audioChunks.current, { type: 'audio/webm' });

        // âœ… ë³€í™˜ ì‹œ íŒŒì¼ ì´ë¦„ ì¶”ê°€
        const mp3Blob = await convertToMp3(webmBlob, 'recording');

        setAudioBlob(mp3Blob);
      };

      recorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error('ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
    }
  };

  const handleStopRecording = () => {
    if (recorderRef.current) {
      recorderRef.current.stop();
      setIsRecording(false);
    }
  };

  const convertToMp3 = (inputBlob: Blob, fileName: string): Promise<File> => {
    return new Promise((resolve, reject) => {
      console.log('ğŸ¤ MP3 ë³€í™˜ ì‹œì‘ - ì›ë³¸ íŒŒì¼ í¬ê¸°:', inputBlob.size, 'íƒ€ì…:', inputBlob.type);

      // âœ… MP3ì´ë©´ ë³€í™˜í•˜ì§€ ì•Šê³  ë°”ë¡œ ë¦¬í„´
      if (inputBlob.type.includes('mp3')) {
        console.warn('âš ï¸ ì´ë¯¸ MP3 íŒŒì¼ì´ë¯€ë¡œ ë³€í™˜ ì—†ì´ ì‚¬ìš©ë©ë‹ˆë‹¤:', fileName);
        resolve(new File([inputBlob], fileName, { type: 'audio/mp3', lastModified: Date.now() }));
        return;
      }

      const reader = new FileReader();
      reader.readAsArrayBuffer(inputBlob);

      reader.onloadend = () => {
        if (!reader.result) {
          console.error('âŒ FileReaderê°€ ë°ì´í„°ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!');
          reject(new Error('FileReader failed to read data'));
          return;
        }

        const audioContext = new AudioContext();
        const arrayBuffer = reader.result as ArrayBuffer;

        audioContext
          .decodeAudioData(arrayBuffer)
          .then((audioBuffer) => {
            if (!audioBuffer) {
              console.error('âŒ PCM ë³€í™˜ ì‹¤íŒ¨: `decodeAudioData()`ê°€ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
              reject(new Error('Failed to decode audio to PCM'));
              return;
            }

            console.log(
              `ğŸ”Š PCM ë³€í™˜ ì™„ë£Œ: ìƒ˜í”Œë ˆì´íŠ¸ ${audioBuffer.sampleRate}Hz, ì±„ë„ ${audioBuffer.numberOfChannels}`
            );

            // ğŸ”¥ PCM ë°ì´í„°ë¥¼ Int16Arrayë¡œ ë³€í™˜
            const numChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const bufferSize = 8192;

            const mp3encoder = new lame.Mp3Encoder(numChannels, sampleRate, 128);
            const mp3Data: Uint8Array[] = [];

            for (let channel = 0; channel < numChannels; channel++) {
              const channelData = audioBuffer.getChannelData(channel);
              if (!channelData || channelData.length === 0) {
                console.error(`âŒ ì±„ë„ ${channel}ì—ì„œ PCM ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.`);
                reject(new Error(`Failed to retrieve PCM data for channel ${channel}`));
                return;
              }

              console.log(`ğŸ§ ì±„ë„ ${channel} PCM ë°ì´í„° ê¸¸ì´:`, channelData.length);

              for (let i = 0; i < channelData.length; i += bufferSize) {
                const chunk = channelData.slice(i, i + bufferSize);
                const pcmChunk = new Int16Array(chunk.length);

                for (let j = 0; j < chunk.length; j++) {
                  pcmChunk[j] = Math.max(-32768, Math.min(32767, chunk[j] * 32768));
                }

                const mp3Buf = mp3encoder.encodeBuffer(pcmChunk);
                if (!mp3Buf || mp3Buf.length === 0) {
                  console.error('âŒ MP3 ë³€í™˜ ì‹¤íŒ¨: encodeBuffer()ê°€ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ ëª»í•¨');
                  reject(new Error('MP3 encoding failed'));
                  return;
                }

                mp3Data.push(mp3Buf);
              }
            }

            const finalMp3Buffer = mp3encoder.flush();
            if (finalMp3Buffer.length > 0) {
              mp3Data.push(finalMp3Buffer);
            }

            const mp3Blob = new Blob(mp3Data, { type: 'audio/mp3' });

            console.log('âœ… MP3 ë³€í™˜ ì™„ë£Œ - ë³€í™˜ëœ íŒŒì¼ í¬ê¸°:', mp3Blob.size);

            const mp3File = new File([mp3Blob], fileName.replace(/\.[^/.]+$/, '') + '.mp3', {
              type: 'audio/mp3',
              lastModified: Date.now(),
            });

            console.log('âœ… ìµœì¢… MP3 íŒŒì¼:', mp3File.name, '- í¬ê¸°:', mp3File.size);
            resolve(mp3File);
          })
          .catch((error) => {
            console.error('âŒ PCM ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
            reject(new Error('PCM conversion failed'));
          });
      };

      reader.onerror = () => {
        console.error('âŒ FileReaderì—ì„œ ì˜¤ë¥˜ ë°œìƒ!');
        reject(new Error('Error reading file'));
      };
    });
  };

  const handleUpload = async () => {
    if (!file && !audioBlob) {
      alert('íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ ë…¹ìŒì„ í•´ì£¼ì„¸ìš”.');
      return;
    }

    let uploadFile = file || new File([audioBlob!], 'recording.mp3', { type: 'audio/mp3' });

    console.log('ğŸš€ ì›ë³¸ íŒŒì¼ íƒ€ì…:', uploadFile.type, 'í¬ê¸°:', uploadFile.size);

    // âœ… MP3ê°€ ì•„ë‹ˆë©´ ë³€í™˜ ì‹¤í–‰
    if (!uploadFile.type.includes('mp3')) {
      console.warn('âš ï¸ MP3ë¡œ ë³€í™˜ ì¤‘...');
      uploadFile = await convertToMp3(uploadFile, uploadFile.name);
      console.log('ğŸ§ ë³€í™˜ëœ MP3 íŒŒì¼ íƒ€ì…:', uploadFile.type, 'í¬ê¸°:', uploadFile.size);
    }

    setLoading(true);
    setProgress(5);

    try {
      const formData = new FormData();
      formData.append('file', uploadFile);

      console.log('ğŸš€ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...', uploadFile.name, 'í¬ê¸°:', uploadFile.size);

      const uploadResponse = await axios.post('https://api.assemblyai.com/v2/upload', formData, {
        headers: { Authorization: API_KEY },
      });

      const audioUrl = uploadResponse.data.upload_url;
      setProgress(30);
      console.log('âœ… ì—…ë¡œë“œ ì„±ê³µ:', audioUrl);

      const response = await axios.post(
        'https://api.assemblyai.com/v2/transcript',
        { audio_url: audioUrl, speaker_labels: true, language_code: 'ko' },
        { headers: { Authorization: API_KEY, 'Content-Type': 'application/json' } }
      );

      const transcriptId = response.data.id;
      setProgress(35);
      console.log('ğŸ” í™”ì ë¶„ì„ ì‹œì‘:', transcriptId);

      let transcript;
      while (true) {
        const transcriptResponse = await axios.get(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
          headers: { Authorization: API_KEY },
        });

        if (transcriptResponse.data.status === 'completed') {
          transcript = transcriptResponse.data.utterances;
          setProgress(100);
          console.log('âœ… í™”ì ë¶„ì„ ì™„ë£Œ!');
          break;
        } else {
          setProgress((prev) => Math.min(prev + 5, 95));
          await new Promise((resolve) => setTimeout(resolve, 3000));
        }
      }

      onTranscript(transcript);
    } catch (error) {
      console.error('âŒ ì˜¤ë¥˜ ë°œìƒ:', error);
      setProgress(0);
    } finally {
      setLoading(false);
    }
  };

  return (
    <>
      <RecorderContainer>
        <Timer>â³ {time} ì´ˆ</Timer>
        <RecordButton onClick={isRecording ? handleStopRecording : handleStartRecording} $isRecording={isRecording}>
          {isRecording ? <FaStop /> : <FaMicrophone />}
        </RecordButton>
      </RecorderContainer>

      <FileForm>
        <input type="file" id="fileUpload" onChange={handleFileChange} />
        <label className="fileUploadlabel" htmlFor="fileUpload">
          {file ? file.name : 'ì„ íƒëœ íŒŒì¼ ì—†ìŒ'}
        </label>

        <Button onClick={handleUpload} disabled={loading}>
          {loading ? 'ì²˜ë¦¬ ì¤‘...' : 'ìŒì„± ë¶„ì„ ì‹œì‘'}
        </Button>
      </FileForm>

      {loading && (
        <div style={{ marginTop: '10px', width: '100%', backgroundColor: '#eee', borderRadius: '10px' }}>
          <div
            style={{
              width: `${progress}%`,
              backgroundColor: '#7c3aed',
              color: 'white',
              textAlign: 'center',
              fontSize: '14px',
              borderRadius: '10px 0 0 10px',
              transition: 'All .3s',
            }}
          >
            {progress}%
          </div>
        </div>
      )}
    </>
  );
};

export default AudioProcessor;
