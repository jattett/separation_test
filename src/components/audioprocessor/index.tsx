import React, { useState, useRef, useEffect } from "react";
import axios from "axios";
import { FaMicrophone, FaStop } from "react-icons/fa"; // ğŸ”¥ ë§ˆì´í¬ & ì •ì§€ ì•„ì´ì½˜ ì¶”ê°€
import styled, { keyframes, css } from "styled-components";
import { Button, FileForm } from "./Styled";

const API_KEY = "9908b0de5b704b80a20bb799d7803ad9";

interface Transcript {
  speaker: number;
  text: string;
}

interface Props {
  onTranscript: (transcript: Transcript[]) => void;
}

const pulse = keyframes`
  0% { box-shadow: 0 0 10px rgba(255, 0, 0, 0.3); }
  50% { box-shadow: 0 0 20px rgba(255, 0, 0, 0.7); }
  100% { box-shadow: 0 0 10px rgba(255, 0, 0, 0.3); }
`;

const wave = keyframes`
  0% { transform: scale(1); opacity: 0.6; }
  50% { transform: scale(1.2); opacity: 1; }
  100% { transform: scale(1); opacity: 0.6; }
`;

const RecorderContainer = styled.div`
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  padding: 20px;
`;

const Timer = styled.p`
  font-size: 18px;
  font-weight: bold;
  color: #333;
`;

const RecordButton = styled.button<{
  $isRecording: boolean;
  $isSpeaking: boolean;
}>`
  margin-top: 10px;
  background-color: ${(props) => (props.$isRecording ? "#ff4d4d" : "#4caf50")};
  border: none;
  color: white;
  width: 60px;
  height: 60px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 24px;
  cursor: pointer;
  transition: all 0.3s ease-in-out;
  box-shadow: ${(props) =>
    props.$isRecording
      ? "0 0 20px rgba(255, 0, 0, 0.7)"
      : "0 0 10px rgba(0, 255, 0, 0.7)"};

  ${(props) =>
    props.$isRecording &&
    css`
      animation: ${pulse} 1.5s infinite;
    `}

  /* ğŸ”¥ ë…¹ìŒ ì¤‘ì¼ ë•Œë§Œ ìŒì„± ê°ì§€ ì• ë‹ˆë©”ì´ì…˜ ì ìš© */
  ${(props) =>
    props.$isRecording &&
    props.$isSpeaking &&
    css`
      animation: ${wave} 0.5s infinite ease-in-out;
    `}
  &:hover {
    scale: 1.1;
  }
`;

const AudioProcessor: React.FC<Props> = ({ onTranscript }) => {
  const [loading, setLoading] = useState<boolean>(false);
  const [progress, setProgress] = useState<number>(0);
  const [file, setFile] = useState<File | null>(null);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null); // ğŸ”¥ ë…¹ìŒëœ íŒŒì¼ ì €ì¥ ë³€ìˆ˜
  const [time, setTime] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false); // ğŸ”¥ ìŒì„± ê°ì§€ ìƒíƒœ ì¶”ê°€
  const recorderRef = useRef<MediaRecorder | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const timerRef = useRef<number | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);

  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = event.target.files?.[0];
    if (selectedFile) {
      setFile(selectedFile);
      setAudioBlob(null);
      setTime(0);
    }
  };

  useEffect(() => {
    if (isRecording) {
      timerRef.current = window.setInterval(() => {
        setTime((prev) => prev + 1);
      }, 1000);
    } else {
      if (timerRef.current !== null) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }
  }, [isRecording]);

  const handleStartRecording = async () => {
    try {
      if (window.location.protocol !== "https:") {
        alert("ğŸ”’ HTTPS í™˜ê²½ì—ì„œë§Œ ë…¹ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.");
        return;
      }

      setFile(null); // ê¸°ì¡´ íŒŒì¼ ì´ˆê¸°í™”

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // âœ… ë…¹ìŒ ê¸°ë³¸ í¬ë§·: WebM
      const mimeType = "audio/webm";

      const recorder = new MediaRecorder(stream, { mimeType });
      recorderRef.current = recorder;
      audioChunks.current = [];
      setTime(0);
      setIsSpeaking(false);

      // ğŸ”¥ ìŒì„± ê°ì§€
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      source.connect(analyser);
      analyser.fftSize = 512;
      analyserRef.current = analyser;
      detectSpeaking(analyser);

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.current.push(event.data);
        }
      };

      recorder.onstop = async () => {
        if (audioChunks.current.length === 0) {
          alert("ë…¹ìŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.");
          return;
        }

        // âœ… WebM íŒŒì¼ë¡œ ì €ì¥
        const recordedBlob = new Blob(audioChunks.current, { type: mimeType });

        if (recordedBlob.size < 1000) {
          alert("ë…¹ìŒëœ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
          return;
        }

        // ğŸ”¥ WAV ë˜ëŠ” MP3 ë³€í™˜ ì¶”ê°€
        const convertedFile = await convertToWav(recordedBlob, "recording.wav");

        console.log(
          "ğŸ“ ë³€í™˜ ì™„ë£Œ - íŒŒì¼ í¬ê¸°:",
          convertedFile.size,
          "íƒ€ì…:",
          convertedFile.type
        );
        setAudioBlob(convertedFile);
        setIsSpeaking(false);
      };

      recorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error("ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:", error);
      alert("âŒ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
    }
  };

  // ğŸ”¥ ìŒì„± ê°ì§€ í•¨ìˆ˜ ì¶”ê°€
  const detectSpeaking = (analyser: AnalyserNode) => {
    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    const checkVolume = () => {
      analyser.getByteFrequencyData(dataArray);
      const volume = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

      setIsSpeaking(volume > 10); // ğŸ”¥ ë³¼ë¥¨ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒì´ë©´ ê°ì§€
      requestAnimationFrame(checkVolume);
    };

    checkVolume();
  };

  const handleStopRecording = () => {
    if (recorderRef.current) {
      recorderRef.current.stop();
      setIsRecording(false);
      setIsSpeaking(false);
    }
  };

  /** ğŸ”¥ WebM â†’ WAV ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€ */
  const convertToWav = async (
    inputBlob: Blob,
    fileName: string
  ): Promise<File> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsArrayBuffer(inputBlob);

      reader.onloadend = async () => {
        if (!reader.result) {
          reject(new Error("FileReader failed to read data"));
          return;
        }

        const arrayBuffer = reader.result as ArrayBuffer;
        const wavBlob = new Blob([arrayBuffer], { type: "audio/wav" });

        const wavFile = new File([wavBlob], fileName, {
          type: "audio/wav",
          lastModified: Date.now(),
        });

        resolve(wavFile);
      };

      reader.onerror = () => {
        reject(new Error("Error reading file"));
      };
    });
  };

  const convertToMpeg = async (
    inputBlob: Blob,
    fileName: string
  ): Promise<File> => {
    return new Promise((resolve, reject) => {
      console.log(
        "ğŸ¤ MPEG ë³€í™˜ ì‹œì‘ - ì›ë³¸ íŒŒì¼ í¬ê¸°:",
        inputBlob.size,
        "íƒ€ì…:",
        inputBlob.type
      );

      // âœ… ì´ë¯¸ MPEG(MP4) í˜•ì‹ì´ë©´ ë³€í™˜ ì—†ì´ ì‚¬ìš©
      if (inputBlob.type.includes("mpeg") || inputBlob.type.includes("mpeg")) {
        console.warn("âš ï¸ ì´ë¯¸ MPEG íŒŒì¼ì´ë¯€ë¡œ ë³€í™˜ ì—†ì´ ì‚¬ìš©ë©ë‹ˆë‹¤:", fileName);
        resolve(
          new File([inputBlob], fileName, {
            type: "audio/mpeg",
            lastModified: Date.now(),
          })
        );
        return;
      }

      const reader = new FileReader();
      reader.readAsArrayBuffer(inputBlob);

      reader.onloadend = async () => {
        if (!reader.result) {
          console.error("âŒ FileReaderê°€ ë°ì´í„°ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!");
          reject(new Error("FileReader failed to read data"));
          return;
        }

        try {
          // ğŸ”¥ AudioContextë¡œ PCM ë°ì´í„° ë³€í™˜
          const audioContext = new AudioContext();
          const arrayBuffer = reader.result as ArrayBuffer;
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          if (!audioBuffer) {
            console.error(
              "âŒ `decodeAudioData()`ê°€ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            );
            reject(new Error("Failed to decode audio to PCM"));
            return;
          }

          console.log(
            "ğŸ”Š PCM ë³€í™˜ ì™„ë£Œ: ìƒ˜í”Œë ˆì´íŠ¸",
            audioBuffer.sampleRate,
            "Hz"
          );

          // ğŸ”¥ MP4 ë³€í™˜ ë¡œì§ ì¶”ê°€
          const mp4Blob = new Blob([arrayBuffer], { type: "audio/mpeg" });

          console.log("âœ… MPEG ë³€í™˜ ì™„ë£Œ - ë³€í™˜ëœ íŒŒì¼ í¬ê¸°:", mp4Blob.size);

          // âœ… Blob â†’ File ë³€í™˜ (ì´ë¦„ ì¶”ê°€)
          const mp4File = new File(
            [mp4Blob],
            fileName.replace(/\.[^/.]+$/, "") + ".mp4",
            {
              type: "audio/mpeg",
              lastModified: Date.now(),
            }
          );

          console.log(
            "âœ… ìµœì¢… MPEG íŒŒì¼:",
            mp4File.name,
            "- í¬ê¸°:",
            mp4File.size
          );
          resolve(mp4File);
        } catch (error) {
          console.error("âŒ PCM ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
          reject(new Error("PCM conversion failed"));
        }
      };

      reader.onerror = () => {
        console.error("âŒ FileReaderì—ì„œ ì˜¤ë¥˜ ë°œìƒ!");
        reject(new Error("Error reading file"));
      };
    });
  };

  const handleUpload = async () => {
    if (!file && !audioBlob) {
      alert("íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ ë…¹ìŒì„ í•´ì£¼ì„¸ìš”.");
      return;
    }

    let uploadFile =
      file || new File([audioBlob!], "recording.mpeg", { type: "audio/mpeg" });

    console.log(
      "ğŸš€ ì—…ë¡œë“œ ì¤€ë¹„ - íŒŒì¼ íƒ€ì…:",
      uploadFile.type,
      "í¬ê¸°:",
      uploadFile.size
    );

    // âœ… MP4ê°€ ì•„ë‹ˆë©´ ë³€í™˜ ì‹¤í–‰
    if (!uploadFile.type.includes("mp4") && !uploadFile.type.includes("mpeg")) {
      console.warn("âš ï¸ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤...");
      uploadFile = await convertToMpeg(uploadFile, uploadFile.name);
    }

    setLoading(true);
    setProgress(5);

    try {
      const formData = new FormData();
      formData.append("file", uploadFile);

      console.log(
        "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...",
        uploadFile.name,
        "í¬ê¸°:",
        uploadFile.size
      );

      const uploadResponse = await axios.post(
        "https://api.assemblyai.com/v2/upload",
        formData,
        {
          headers: { Authorization: API_KEY },
        }
      );

      console.log("âœ… ì—…ë¡œë“œ ì„±ê³µ:", uploadResponse.data);

      const audioUrl = uploadResponse.data.upload_url;
      setProgress(30);

      const response = await axios.post(
        "https://api.assemblyai.com/v2/transcript",
        { audio_url: audioUrl, speaker_labels: true, language_code: "ko" },
        {
          headers: {
            Authorization: API_KEY,
            "Content-Type": "application/json",
          },
        }
      );

      const transcriptId = response.data.id;
      setProgress(35);
      console.log("ğŸ” í™”ì ë¶„ì„ ì‹œì‘:", transcriptId);

      let transcript = null;
      while (true) {
        const transcriptResponse = await axios.get(
          `https://api.assemblyai.com/v2/transcript/${transcriptId}`,
          {
            headers: { Authorization: API_KEY },
          }
        );

        if (transcriptResponse.data.status === "completed") {
          transcript = transcriptResponse.data.utterances || [];
          setProgress(100);
          console.log("âœ… í™”ì ë¶„ì„ ì™„ë£Œ!");
          break;
        } else {
          setProgress((prev) => Math.min(prev + 5, 95));
          await new Promise((resolve) => setTimeout(resolve, 3000));
        }
      }

      onTranscript(transcript || []);
    } catch (error) {
      console.error("âŒ ì˜¤ë¥˜ ë°œìƒ:", error);
      setProgress(0);
    } finally {
      setLoading(false);
    }
  };

  return (
    <>
      <RecorderContainer>
        <Timer>â³ {time} ì´ˆ</Timer>
        <RecordButton
          onClick={isRecording ? handleStopRecording : handleStartRecording}
          $isRecording={isRecording}
          $isSpeaking={isSpeaking} // ğŸ”¥ ìŒì„±ì´ ê°ì§€ë˜ë©´ ì• ë‹ˆë©”ì´ì…˜ ì¶”ê°€
        >
          {isRecording ? <FaStop /> : <FaMicrophone />}
        </RecordButton>
      </RecorderContainer>

      <FileForm>
        <input type="file" id="fileUpload" onChange={handleFileChange} />
        <label className="fileUploadlabel" htmlFor="fileUpload">
          {file ? file.name : "ì„ íƒëœ íŒŒì¼ ì—†ìŒ"}
        </label>

        <Button onClick={handleUpload} disabled={loading}>
          {loading ? "ì²˜ë¦¬ ì¤‘..." : "ìŒì„± ë¶„ì„ ì‹œì‘"}
        </Button>
      </FileForm>

      {loading && (
        <div
          style={{
            marginTop: "10px",
            width: "100%",
            backgroundColor: "#eee",
            borderRadius: "10px",
            maxWidth: "400px",
          }}
        >
          <div
            style={{
              width: `${progress}%`,
              backgroundColor: "#7c3aed",
              color: "white",
              textAlign: "center",
              fontSize: "14px",
              borderRadius: "10px 0 0 10px",
              transition: "All .3s",
              paddingLeft: "10px",
            }}
          >
            {progress}%
          </div>
        </div>
      )}
    </>
  );
};

export default AudioProcessor;
